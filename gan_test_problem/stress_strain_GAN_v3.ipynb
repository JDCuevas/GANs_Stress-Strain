{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using a GAN to Generate Stress-strain Curves\n",
    "\n",
    "## Problem Definition\n",
    "\n",
    "Assuming bi-linear stress strain behavior of a material (characterized by $\\sigma_y$, $E$, and $H$), generate sample stress-strain curves based on some initial samples of a stress-strain curve distrbution. \n",
    "\n",
    "<img src=\"bilinear.png\" alt=\"Drawing\" style=\"width: 300px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating the training data\n",
    "\n",
    "The training samples will be gathered by asuming independent, normal distributions for $\\sigma_y$, $E$, and $H$.\n",
    "\n",
    "  * $\\sigma_y \\sim \\mathcal{N}(\\mu=10, \\sigma=0.5)$\n",
    "  * $E \\sim \\mathcal{N}(\\mu=1000, \\sigma=50)$\n",
    "  * $H \\sim \\mathcal{N}(\\mu=50, \\sigma=5)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stress(strains, E, s_y, H):\n",
    "    e_y = s_y / E\n",
    "    elastic_strains = strains.copy()\n",
    "    elastic_strains[elastic_strains > e_y] = e_y\n",
    "    plastic_strains = strains - elastic_strains\n",
    "    stresses = elastic_strains*E + plastic_strains*H\n",
    "    return stresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_samples(max_strain, n_strain, n_samples):\n",
    "    strain = np.linspace(0, max_strain, n_strain + 1)[1:]\n",
    "    stresses = np.empty((n_samples, n_strain))\n",
    "    for i in range(n_samples):\n",
    "        E = np.random.normal(1000, 50)\n",
    "        s_y = np.random.normal(10, 0.5)\n",
    "        H = np.random.normal(50, 5)\n",
    "        stresses[i] = get_stress(strain, E, s_y, H)\n",
    "    return stresses, strain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make training data:\n",
    "\n",
    "  * rows in stress_mat correspond to the stresses in a single stress strain curve (i.e. 1 sample)\n",
    "  * columns in stress_mat correspond to a single strain value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SAMPLES = 100000\n",
    "MAX_STRAIN = 0.02\n",
    "NUM_STRAINS = 10\n",
    "\n",
    "stress_mat, strains = generate_samples(MAX_STRAIN, NUM_STRAINS, N_SAMPLES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the training distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f01ab7bac8b452b8b51eb6ae8962851",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.01, description='x', max=0.02, step=0.002), Output()), _dom_classes=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_hist(x)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ipywidgets import interact\n",
    "import ipywidgets as widgets\n",
    "\n",
    "def plot_hist(x):\n",
    "    fig, (ax_left, ax_right) = plt.subplots(1, 2, gridspec_kw={'width_ratios': [2, 1]},\n",
    "                                       figsize=(16, 7))\n",
    "    \n",
    "    sns.violinplot(data=pd.DataFrame(data=stress_mat, columns=np.round(strains, 3)), \n",
    "                   ax=ax_left)\n",
    "    ax_left.set(xlabel='strain', ylabel='stress')\n",
    "    \n",
    "    itemindex = np.argmin(abs(strains-x))\n",
    "    sns.distplot(stress_mat[:, itemindex], bins=20)\n",
    "    ax_right.set(xlim=(np.min(stress_mat), np.max(stress_mat)),\n",
    "                 xlabel='stresses at strain of %.3f' % strains[itemindex])\n",
    "    \n",
    "interact(plot_hist, x=(0.0, 0.02, 0.002))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a GAN to produce samples that match this distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "N_SAMPLES = 2560000\n",
    "BATCH_SIZE = 256\n",
    "ITERATIONS = int(N_SAMPLES/BATCH_SIZE)\n",
    "TRAIN_STEPS = 10\n",
    "NOISE_DIM = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Prepare dataset\n",
    "\n",
    "* #### Normalize and shuffle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(data):\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(data)\n",
    "    standardized_data = scaler.transform(data)\n",
    "    \n",
    "    return standardized_data, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(data):\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(data)\n",
    "    normalized_data = scaler.transform(data)\n",
    "    \n",
    "    return normalized_data, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch(batch_size, preprocessing):\n",
    "    stresses, strain = generate_samples(MAX_STRAIN, NUM_STRAINS, batch_size)\n",
    "    batch = []\n",
    "    \n",
    "    for curve in stresses:\n",
    "        curve = np.concatenate((np.expand_dims(np.array(strains), -1), np.expand_dims(curve, -1)), axis=1)\n",
    "        preprocessed_curve, scaler = preprocessing(curve)\n",
    "        batch.append(preprocessed_curve)\n",
    "            \n",
    "    return np.array(batch), scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [11:28<00:00, 14.84it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = []\n",
    "\n",
    "for i in tqdm(range(ITERATIONS)):\n",
    "    standardized_sample, scaler = generate_batch(BATCH_SIZE, standardize)\n",
    "    dataset.append(standardized_sample)\n",
    "\n",
    "dataset = np.array(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create Models\n",
    "\n",
    "* #### Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_generator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Input(shape=(10,2)))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(32, use_bias=False))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "    \n",
    "    model.add(layers.Dense(32, use_bias=False))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    \n",
    "    model.add(layers.Dense(20, use_bias=False))\n",
    "    model.add(layers.Reshape((10,2)))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                640       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v2 (Batc (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                1024      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v2_1 (Ba (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 20)                640       \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 10, 2)             0         \n",
      "=================================================================\n",
      "Total params: 2,560\n",
      "Trainable params: 2,432\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator = make_generator_model()\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* #### Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_discriminator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Input(shape=(10,2)))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(32))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    \n",
    "    model.add(layers.Dense(32))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    \n",
    "    model.add(layers.Dense(20))\n",
    "    model.add(layers.Dense(1))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 32)                672       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 20)                660       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 2,409\n",
      "Trainable params: 2,409\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator = make_discriminator_model()\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Define loss and optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method returns a helper function to compute cross entropy loss\n",
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* #### Discriminator loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* #### Generator loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* #### Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_optimizer = tf.keras.optimizers.RMSprop(1e-3)\n",
    "discriminator_optimizer = tf.keras.optimizers.RMSprop(1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* #### Save checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './v3_training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
    "                                 discriminator_optimizer=discriminator_optimizer,\n",
    "                                 generator=generator,\n",
    "                                 discriminator=discriminator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This annotation causes the function to be \"compiled\".\n",
    "@tf.function\n",
    "def train_step(batch, noise):\n",
    "    \n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        generated_batch = generator(noise, training=True)\n",
    "\n",
    "        real_output = discriminator(batch, training=True)\n",
    "        fake_output = discriminator(generated_batch, training=True)\n",
    "        gen_loss = generator_loss(fake_output)\n",
    "        disc_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
    "    \n",
    "    return disc_loss, gen_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs):\n",
    "    for epoch in range(epochs):\n",
    "        start = time.time()\n",
    "        \n",
    "        for i in tqdm(range(ITERATIONS)):\n",
    "            iter_start = time.time()\n",
    "            \n",
    "            sample_batch = dataset[i]\n",
    "            np.random.shuffle(sample_batch)\n",
    "            noise = tf.random.normal([BATCH_SIZE, NOISE_DIM])\n",
    "\n",
    "            for step in range(TRAIN_STEPS):\n",
    "                disc_loss, gen_loss = train_step(sample_batch, noise)\n",
    "\n",
    "            if (i + 1) % 1000 == 0:\n",
    "                print('Time for iteration {} is {} sec'.format(i + 1, time.time()-iter_start))\n",
    "                print(\"Discriminator loss: {0:.4f}\\t Generator loss: {0:.4f}\\n\".format(disc_loss.numpy(), gen_loss.numpy()))\n",
    "\n",
    "        # Save the model every 15 epochs\n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "        print('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
    "        print(\"Discriminator loss: {0:.4f}\\t Generator loss: {0:.4f}\\n\".format(disc_loss.numpy(), gen_loss.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1012/10000 [00:15<01:49, 82.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for iteration 1000 is 0.011893987655639648 sec\n",
      "Discriminator loss: 0.8217\t Generator loss: 0.8217\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2011/10000 [00:27<01:36, 82.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for iteration 2000 is 0.011176109313964844 sec\n",
      "Discriminator loss: 0.6152\t Generator loss: 0.6152\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3010/10000 [00:39<01:24, 82.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for iteration 3000 is 0.012073755264282227 sec\n",
      "Discriminator loss: 0.5924\t Generator loss: 0.5924\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4009/10000 [00:52<01:12, 82.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for iteration 4000 is 0.011708736419677734 sec\n",
      "Discriminator loss: 0.9483\t Generator loss: 0.9483\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5008/10000 [01:04<01:01, 81.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for iteration 5000 is 0.012375354766845703 sec\n",
      "Discriminator loss: 0.3241\t Generator loss: 0.3241\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6016/10000 [01:16<00:47, 83.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for iteration 6000 is 0.011698246002197266 sec\n",
      "Discriminator loss: 0.6803\t Generator loss: 0.6803\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7015/10000 [01:28<00:35, 83.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for iteration 7000 is 0.011858463287353516 sec\n",
      "Discriminator loss: 0.7118\t Generator loss: 0.7118\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8014/10000 [01:40<00:23, 83.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for iteration 8000 is 0.011668920516967773 sec\n",
      "Discriminator loss: 0.2907\t Generator loss: 0.2907\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9013/10000 [01:52<00:12, 82.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for iteration 9000 is 0.01185154914855957 sec\n",
      "Discriminator loss: 0.2135\t Generator loss: 0.2135\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [02:04<00:00, 80.04it/s]\n",
      "  0%|          | 9/10000 [00:00<02:01, 82.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for iteration 10000 is 0.011899709701538086 sec\n",
      "Discriminator loss: 0.6612\t Generator loss: 0.6612\n",
      "\n",
      "Time for epoch 1 is 124.94568514823914 sec\n",
      "Discriminator loss: 0.6612\t Generator loss: 0.6612\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1016/10000 [00:12<01:49, 82.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for iteration 1000 is 0.012036800384521484 sec\n",
      "Discriminator loss: 0.2385\t Generator loss: 0.2385\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2015/10000 [00:24<01:36, 83.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for iteration 2000 is 0.01230931282043457 sec\n",
      "Discriminator loss: 0.1880\t Generator loss: 0.1880\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3014/10000 [00:36<01:25, 81.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for iteration 3000 is 0.013438940048217773 sec\n",
      "Discriminator loss: 0.4135\t Generator loss: 0.4135\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4013/10000 [00:48<01:12, 82.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for iteration 4000 is 0.012255668640136719 sec\n",
      "Discriminator loss: 0.3656\t Generator loss: 0.3656\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5012/10000 [01:00<01:00, 82.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for iteration 5000 is 0.01151418685913086 sec\n",
      "Discriminator loss: 0.7347\t Generator loss: 0.7347\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6011/10000 [01:12<00:47, 83.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for iteration 6000 is 0.012392759323120117 sec\n",
      "Discriminator loss: 0.3185\t Generator loss: 0.3185\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7010/10000 [01:25<00:36, 82.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for iteration 7000 is 0.012156009674072266 sec\n",
      "Discriminator loss: 0.5384\t Generator loss: 0.5384\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8009/10000 [01:37<00:24, 82.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for iteration 8000 is 0.012403726577758789 sec\n",
      "Discriminator loss: 0.2246\t Generator loss: 0.2246\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9008/10000 [01:49<00:12, 82.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for iteration 9000 is 0.012613296508789062 sec\n",
      "Discriminator loss: 0.3474\t Generator loss: 0.3474\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [02:01<00:00, 82.44it/s]\n",
      "  0%|          | 9/10000 [00:00<02:03, 80.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for iteration 10000 is 0.012633085250854492 sec\n",
      "Discriminator loss: 0.4253\t Generator loss: 0.4253\n",
      "\n",
      "Time for epoch 2 is 121.30765891075134 sec\n",
      "Discriminator loss: 0.4253\t Generator loss: 0.4253\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1016/10000 [00:12<01:50, 81.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for iteration 1000 is 0.011867046356201172 sec\n",
      "Discriminator loss: 0.4135\t Generator loss: 0.4135\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2015/10000 [00:24<01:36, 82.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for iteration 2000 is 0.011737585067749023 sec\n",
      "Discriminator loss: 0.4901\t Generator loss: 0.4901\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3014/10000 [00:36<01:24, 82.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for iteration 3000 is 0.011821746826171875 sec\n",
      "Discriminator loss: 0.4507\t Generator loss: 0.4507\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4013/10000 [00:48<01:12, 82.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for iteration 4000 is 0.011688709259033203 sec\n",
      "Discriminator loss: 0.2929\t Generator loss: 0.2929\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5012/10000 [01:00<01:01, 81.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for iteration 5000 is 0.012151718139648438 sec\n",
      "Discriminator loss: 0.2811\t Generator loss: 0.2811\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6011/10000 [01:12<00:48, 81.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for iteration 6000 is 0.011969327926635742 sec\n",
      "Discriminator loss: 1.8642\t Generator loss: 1.8642\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7010/10000 [01:25<00:36, 82.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for iteration 7000 is 0.012036323547363281 sec\n",
      "Discriminator loss: 0.1978\t Generator loss: 0.1978\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8008/10000 [01:37<00:26, 76.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for iteration 8000 is 0.012639760971069336 sec\n",
      "Discriminator loss: 0.0895\t Generator loss: 0.0895\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9016/10000 [01:49<00:11, 82.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for iteration 9000 is 0.01242971420288086 sec\n",
      "Discriminator loss: 0.2041\t Generator loss: 0.2041\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [02:01<00:00, 82.18it/s]\n",
      "  0%|          | 9/10000 [00:00<02:02, 81.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for iteration 10000 is 0.01226043701171875 sec\n",
      "Discriminator loss: 0.4664\t Generator loss: 0.4664\n",
      "\n",
      "Time for epoch 3 is 121.68046736717224 sec\n",
      "Discriminator loss: 0.4664\t Generator loss: 0.4664\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1013/10000 [00:12<01:50, 81.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for iteration 1000 is 0.012032032012939453 sec\n",
      "Discriminator loss: 0.2269\t Generator loss: 0.2269\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2012/10000 [00:24<01:36, 82.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for iteration 2000 is 0.01165008544921875 sec\n",
      "Discriminator loss: 0.2924\t Generator loss: 0.2924\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3011/10000 [00:36<01:25, 82.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for iteration 3000 is 0.012015581130981445 sec\n",
      "Discriminator loss: 0.2965\t Generator loss: 0.2965\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4010/10000 [00:48<01:12, 82.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for iteration 4000 is 0.01187896728515625 sec\n",
      "Discriminator loss: 3.8692\t Generator loss: 3.8692\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5009/10000 [01:00<01:00, 83.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for iteration 5000 is 0.011686086654663086 sec\n",
      "Discriminator loss: 0.2458\t Generator loss: 0.2458\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6008/10000 [01:13<00:48, 82.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for iteration 6000 is 0.012744903564453125 sec\n",
      "Discriminator loss: 0.1579\t Generator loss: 0.1579\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7016/10000 [01:25<00:35, 82.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for iteration 7000 is 0.012212991714477539 sec\n",
      "Discriminator loss: 0.5993\t Generator loss: 0.5993\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8015/10000 [01:37<00:24, 82.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for iteration 8000 is 0.011350870132446289 sec\n",
      "Discriminator loss: 0.1626\t Generator loss: 0.1626\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9014/10000 [01:49<00:12, 81.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for iteration 9000 is 0.011897802352905273 sec\n",
      "Discriminator loss: 0.3562\t Generator loss: 0.3562\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [02:01<00:00, 82.29it/s]\n",
      "  0%|          | 9/10000 [00:00<02:02, 81.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for iteration 10000 is 0.012502431869506836 sec\n",
      "Discriminator loss: 0.2868\t Generator loss: 0.2868\n",
      "\n",
      "Time for epoch 4 is 121.5257613658905 sec\n",
      "Discriminator loss: 0.2868\t Generator loss: 0.2868\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1009/10000 [00:12<01:47, 83.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for iteration 1000 is 0.011540651321411133 sec\n",
      "Discriminator loss: 0.3837\t Generator loss: 0.3837\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2008/10000 [00:24<01:35, 83.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for iteration 2000 is 0.01161956787109375 sec\n",
      "Discriminator loss: 1.2792\t Generator loss: 1.2792\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3016/10000 [00:36<01:22, 84.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for iteration 3000 is 0.011573314666748047 sec\n",
      "Discriminator loss: 0.3616\t Generator loss: 0.3616\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4015/10000 [00:48<01:12, 82.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for iteration 4000 is 0.011854410171508789 sec\n",
      "Discriminator loss: 0.2017\t Generator loss: 0.2017\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5014/10000 [01:00<00:59, 83.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for iteration 5000 is 0.012046337127685547 sec\n",
      "Discriminator loss: 0.2437\t Generator loss: 0.2437\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6013/10000 [01:12<00:48, 82.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for iteration 6000 is 0.011802911758422852 sec\n",
      "Discriminator loss: 0.3731\t Generator loss: 0.3731\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7012/10000 [01:24<00:36, 82.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for iteration 7000 is 0.012338399887084961 sec\n",
      "Discriminator loss: 0.4652\t Generator loss: 0.4652\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8011/10000 [01:36<00:24, 81.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for iteration 8000 is 0.012411117553710938 sec\n",
      "Discriminator loss: 0.0815\t Generator loss: 0.0815\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9010/10000 [01:48<00:12, 81.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for iteration 9000 is 0.01217198371887207 sec\n",
      "Discriminator loss: 0.1861\t Generator loss: 0.1861\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [02:00<00:00, 83.39it/s]\n",
      "  0%|          | 9/10000 [00:00<02:00, 82.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for iteration 10000 is 0.01190805435180664 sec\n",
      "Discriminator loss: 0.3305\t Generator loss: 0.3305\n",
      "\n",
      "Time for epoch 5 is 120.91113424301147 sec\n",
      "Discriminator loss: 0.3305\t Generator loss: 0.3305\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1016/10000 [00:12<01:48, 83.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for iteration 1000 is 0.011584281921386719 sec\n",
      "Discriminator loss: 0.3061\t Generator loss: 0.3061\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2015/10000 [00:24<01:36, 82.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for iteration 2000 is 0.01144266128540039 sec\n",
      "Discriminator loss: 0.2824\t Generator loss: 0.2824\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3015/10000 [00:36<01:24, 82.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for iteration 3000 is 0.011911392211914062 sec\n",
      "Discriminator loss: 0.3068\t Generator loss: 0.3068\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4014/10000 [00:48<01:12, 82.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for iteration 4000 is 0.012084722518920898 sec\n",
      "Discriminator loss: 0.1520\t Generator loss: 0.1520\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5013/10000 [01:00<00:59, 83.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for iteration 5000 is 0.011625528335571289 sec\n",
      "Discriminator loss: 0.1519\t Generator loss: 0.1519\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6012/10000 [01:12<00:48, 81.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for iteration 6000 is 0.011852025985717773 sec\n",
      "Discriminator loss: 0.1075\t Generator loss: 0.1075\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7011/10000 [01:25<00:36, 81.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for iteration 7000 is 0.01184844970703125 sec\n",
      "Discriminator loss: 0.2584\t Generator loss: 0.2584\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8010/10000 [01:37<00:24, 81.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for iteration 8000 is 0.011642694473266602 sec\n",
      "Discriminator loss: 0.1870\t Generator loss: 0.1870\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9009/10000 [01:49<00:11, 83.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for iteration 9000 is 0.011963129043579102 sec\n",
      "Discriminator loss: 0.3167\t Generator loss: 0.3167\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [02:01<00:00, 82.45it/s]\n",
      "  0%|          | 9/10000 [00:00<01:58, 84.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for iteration 10000 is 0.012797117233276367 sec\n",
      "Discriminator loss: 0.3351\t Generator loss: 0.3351\n",
      "\n",
      "Time for epoch 6 is 121.2908673286438 sec\n",
      "Discriminator loss: 0.3351\t Generator loss: 0.3351\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1010/10000 [00:12<01:46, 84.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for iteration 1000 is 0.011848211288452148 sec\n",
      "Discriminator loss: 0.2708\t Generator loss: 0.2708\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2013/10000 [00:23<01:32, 86.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for iteration 2000 is 0.011142969131469727 sec\n",
      "Discriminator loss: 0.2315\t Generator loss: 0.2315\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3017/10000 [00:35<01:22, 84.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for iteration 3000 is 0.012159585952758789 sec\n",
      "Discriminator loss: 0.2496\t Generator loss: 0.2496\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4010/10000 [00:47<01:13, 81.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for iteration 4000 is 0.012305736541748047 sec\n",
      "Discriminator loss: 0.3312\t Generator loss: 0.3312\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5009/10000 [00:59<01:01, 81.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for iteration 5000 is 0.012293100357055664 sec\n",
      "Discriminator loss: 0.3271\t Generator loss: 0.3271\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6008/10000 [01:11<00:48, 82.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for iteration 6000 is 0.013139963150024414 sec\n",
      "Discriminator loss: 0.2502\t Generator loss: 0.2502\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7016/10000 [01:23<00:36, 82.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for iteration 7000 is 0.011978387832641602 sec\n",
      "Discriminator loss: 0.1763\t Generator loss: 0.1763\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8015/10000 [01:36<00:23, 83.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for iteration 8000 is 0.011965513229370117 sec\n",
      "Discriminator loss: 0.3837\t Generator loss: 0.3837\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9014/10000 [01:48<00:11, 82.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for iteration 9000 is 0.01154780387878418 sec\n",
      "Discriminator loss: 0.2444\t Generator loss: 0.2444\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [02:00<00:00, 83.22it/s]\n",
      "  0%|          | 9/10000 [00:00<02:02, 81.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for iteration 10000 is 0.012148380279541016 sec\n",
      "Discriminator loss: 0.2449\t Generator loss: 0.2449\n",
      "\n",
      "Time for epoch 7 is 120.15855956077576 sec\n",
      "Discriminator loss: 0.2449\t Generator loss: 0.2449\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1014/10000 [00:12<01:50, 81.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for iteration 1000 is 0.011853933334350586 sec\n",
      "Discriminator loss: 0.2656\t Generator loss: 0.2656\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2013/10000 [00:24<01:38, 81.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for iteration 2000 is 0.012272357940673828 sec\n",
      "Discriminator loss: 0.2467\t Generator loss: 0.2467\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3012/10000 [00:36<01:25, 81.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for iteration 3000 is 0.011997699737548828 sec\n",
      "Discriminator loss: 0.4132\t Generator loss: 0.4132\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4011/10000 [00:48<01:12, 82.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for iteration 4000 is 0.012598514556884766 sec\n",
      "Discriminator loss: 0.2536\t Generator loss: 0.2536\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5010/10000 [01:00<01:00, 82.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for iteration 5000 is 0.012176036834716797 sec\n",
      "Discriminator loss: 0.3994\t Generator loss: 0.3994\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6009/10000 [01:13<00:48, 82.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for iteration 6000 is 0.012096166610717773 sec\n",
      "Discriminator loss: 0.3524\t Generator loss: 0.3524\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7008/10000 [01:25<00:36, 81.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for iteration 7000 is 0.01315760612487793 sec\n",
      "Discriminator loss: 0.2807\t Generator loss: 0.2807\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8016/10000 [01:37<00:24, 82.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for iteration 8000 is 0.012112855911254883 sec\n",
      "Discriminator loss: 0.1550\t Generator loss: 0.1550\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9015/10000 [01:49<00:12, 81.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for iteration 9000 is 0.011806726455688477 sec\n",
      "Discriminator loss: 0.3829\t Generator loss: 0.3829\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [02:01<00:00, 82.34it/s]\n",
      "  0%|          | 9/10000 [00:00<02:02, 81.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for iteration 10000 is 0.012166976928710938 sec\n",
      "Discriminator loss: 0.4041\t Generator loss: 0.4041\n",
      "\n",
      "Time for epoch 8 is 121.45300698280334 sec\n",
      "Discriminator loss: 0.4041\t Generator loss: 0.4041\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1016/10000 [00:12<01:48, 82.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for iteration 1000 is 0.012624263763427734 sec\n",
      "Discriminator loss: 0.0833\t Generator loss: 0.0833\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2015/10000 [00:24<01:36, 82.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for iteration 2000 is 0.011631250381469727 sec\n",
      "Discriminator loss: 0.3286\t Generator loss: 0.3286\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3014/10000 [00:36<01:24, 82.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for iteration 3000 is 0.011698007583618164 sec\n",
      "Discriminator loss: 0.1973\t Generator loss: 0.1973\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4013/10000 [00:48<01:12, 82.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for iteration 4000 is 0.012028694152832031 sec\n",
      "Discriminator loss: 0.1874\t Generator loss: 0.1874\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5012/10000 [01:00<01:00, 81.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for iteration 5000 is 0.012339353561401367 sec\n",
      "Discriminator loss: 0.3597\t Generator loss: 0.3597\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6011/10000 [01:12<00:48, 81.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for iteration 6000 is 0.012075424194335938 sec\n",
      "Discriminator loss: 0.1854\t Generator loss: 0.1854\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7010/10000 [01:25<00:36, 82.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for iteration 7000 is 0.012192964553833008 sec\n",
      "Discriminator loss: 0.1975\t Generator loss: 0.1975\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8009/10000 [01:37<00:24, 81.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for iteration 8000 is 0.012787580490112305 sec\n",
      "Discriminator loss: 0.1568\t Generator loss: 0.1568\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9009/10000 [01:49<00:12, 81.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for iteration 9000 is 0.011774301528930664 sec\n",
      "Discriminator loss: 0.1319\t Generator loss: 0.1319\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [02:01<00:00, 82.35it/s]\n",
      "  0%|          | 9/10000 [00:00<02:00, 83.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for iteration 10000 is 0.012483835220336914 sec\n",
      "Discriminator loss: 0.2693\t Generator loss: 0.2693\n",
      "\n",
      "Time for epoch 9 is 121.43743371963501 sec\n",
      "Discriminator loss: 0.2693\t Generator loss: 0.2693\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1008/10000 [00:12<01:48, 82.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for iteration 1000 is 0.013163089752197266 sec\n",
      "Discriminator loss: 0.3206\t Generator loss: 0.3206\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2016/10000 [00:24<01:37, 82.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for iteration 2000 is 0.01229095458984375 sec\n",
      "Discriminator loss: 0.0970\t Generator loss: 0.0970\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3015/10000 [00:36<01:24, 82.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for iteration 3000 is 0.012160062789916992 sec\n",
      "Discriminator loss: 0.1320\t Generator loss: 0.1320\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4014/10000 [00:48<01:12, 82.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for iteration 4000 is 0.012124300003051758 sec\n",
      "Discriminator loss: 0.2842\t Generator loss: 0.2842\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5013/10000 [01:00<01:00, 82.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for iteration 5000 is 0.011945962905883789 sec\n",
      "Discriminator loss: 0.3160\t Generator loss: 0.3160\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6013/10000 [01:12<00:47, 83.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for iteration 6000 is 0.011754035949707031 sec\n",
      "Discriminator loss: 0.0623\t Generator loss: 0.0623\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7012/10000 [01:25<00:36, 82.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for iteration 7000 is 0.011873483657836914 sec\n",
      "Discriminator loss: 0.2069\t Generator loss: 0.2069\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8011/10000 [01:37<00:24, 81.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for iteration 8000 is 0.012295961380004883 sec\n",
      "Discriminator loss: 0.2484\t Generator loss: 0.2484\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9010/10000 [01:49<00:12, 81.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for iteration 9000 is 0.011978864669799805 sec\n",
      "Discriminator loss: 0.2970\t Generator loss: 0.2970\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [02:01<00:00, 82.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for iteration 10000 is 0.011790990829467773 sec\n",
      "Discriminator loss: 0.2826\t Generator loss: 0.2826\n",
      "\n",
      "Time for epoch 10 is 121.44710683822632 sec\n",
      "Discriminator loss: 0.2826\t Generator loss: 0.2826\n",
      "\n",
      "CPU times: user 1h 7min 22s, sys: 9min 21s, total: 1h 16min 43s\n",
      "Wall time: 20min 16s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train(EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_examples(real, generated):\n",
    "    r_ax = plt.scatter(real[:,:,0], real[:,:,1], label='Real Data')\n",
    "    g_ax = plt.scatter(generated[:,:,0], generated[:,:,1], label='Generated Data', color='orange')\n",
    "    plt.legend()\n",
    "    plt.title('Samples')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 10, 2)\n",
      "(256, 10, 2)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_examples = 256\n",
    "seed = tf.random.normal([num_examples, NOISE_DIM])\n",
    "#seed = tf.random.uniform(minval= -1., maxval= 1., shape=[BATCH_SIZE, NOISE_DIM])\n",
    "\n",
    "pred = generator(seed, training=False)\n",
    "unscaled_pred = scaler.inverse_transform(pred)\n",
    "\n",
    "samples, scaler = generate_batch(batch_size=num_examples, preprocessing=standardize)\n",
    "unscaled_samples = scaler.inverse_transform(samples)\n",
    "\n",
    "print(unscaled_samples.shape)\n",
    "print(unscaled_pred.shape)\n",
    "\n",
    "plot_examples(unscaled_samples, unscaled_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9772013\n",
      "(256, 10, 2)\n",
      "12.492057964542855\n"
     ]
    }
   ],
   "source": [
    "print(np.min(unscaled_pred[:,:,1]))\n",
    "print(unscaled_pred[:,:].shape)\n",
    "print(np.max(stress_mat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86c272e657274e6e860fee92b44b6bfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.01, description='x', max=0.02, step=0.002), Output()), _dom_classes=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_hist_results(x)>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def plot_hist_results(x):\n",
    "    fig, (ax_left, ax_right) = plt.subplots(1, 2, gridspec_kw={'width_ratios': [2, 1]},\n",
    "                                       figsize=(16, 7))\n",
    "    \n",
    "    sns.violinplot(data=pd.DataFrame(data=unscaled_pred[:,:,1], columns=np.round(strains, 3)), \n",
    "                   ax=ax_left)\n",
    "    ax_left.set(xlabel='strain', ylabel='stress')\n",
    "    \n",
    "    itemindex = np.argmin(abs(strains-x))\n",
    "    sns.distplot(unscaled_pred[:, itemindex, 1], bins=20)\n",
    "    ax_right.set(xlim=(np.min(unscaled_pred[:,:,1]), np.max(unscaled_pred[:,:,1])),\n",
    "                 xlabel='stresses at strain of %.3f' % strains[itemindex])\n",
    "    \n",
    "interact(plot_hist_results, x=(0.0, 0.02, 0.002))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
